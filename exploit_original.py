import numpy as np
import networkx as nx
from scipy.sparse.csgraph import connected_components

class ResourcePool:
    def __init__(self, initial_stock, max_stock, growth_rate):
        self.stock = initial_stock
        self.max_stock = max_stock
        self.growth_rate = growth_rate

    def step(self, dt, strategy):
        s0 = self.stock
        smax = self.max_stock
        g = self.growth_rate
        E = g * 0.5 * (3 - 2 * strategy)
        b = g - E
        gs0 = g * s0
        s1 = s0 * smax * b / ((smax * b - gs0) * np.exp(-b * dt) + gs0)
        harvest = E * s1
        self.stock = s1

        return harvest

class Agent:
    def __init__(self, strategy, rationality, resource_pool):
        self.strategy = strategy
        self.rationality = rationality
        self.resource_pool = resource_pool
        self.update_time = np.random.exponential(1.0)

    def decide_update(self, harvest_self, harvest_neighbor):
        dH = harvest_neighbor - harvest_self
        imitation_probability = 0.5 * (np.tanh(self.rationality * dH) + 1)
        if np.random.rand() < imitation_probability:
            return 'imitate'
        return 'none'
    
    def perform_action(self, dt):
        return self.resource_pool.step(dt, self.strategy)

class MultiAgentTrainer:
    def __init__(self, adjacency_matrix, population, update_timescale):
        self.num_agents = adjacency_matrix.shape[0]
        self.adjacency_matrix = adjacency_matrix
        self.update_timescale = update_timescale
        self.population = population
        self.consensus = self.check_for_consensus()
        self.current_time = 0

    def check_for_consensus(self):
        cc = connected_components(self.adjacency_matrix, directed=False)[1]
        return all(len(np.unique([self.population[i].strategy for i in (cc == c).nonzero()[0]])) == 1 for c in np.unique(cc))

    def find_update_candidates(self):
        for _ in range(100 * self.num_agents):
            agent_index = np.argmin([agent.update_time for agent in self.population])
            agent = self.population[agent_index]
            update_time = agent.update_time
            agent.update_time += np.random.exponential(self.update_timescale)
            neighbors = self.adjacency_matrix[agent_index].nonzero()[0]

            if len(neighbors) > 0:
                neighbor_index = np.random.choice(neighbors)
                if self.population[neighbor_index].strategy != agent.strategy:
                    return agent_index, neighbor_index, update_time
        return -1, -1, 0.0

    def run(self, num_steps=1000000000):
        for _ in range(num_steps):

            # Find next agent to update and pick a neighbor
            agent_index, neighbor_index, update_time = self.find_update_candidates()
            if self.consensus:
                return 1  # end with consensus
            if agent_index == -1:
                return -1  # no update candidates found (BAD)

            # Step all agents until update_time
            dt = update_time - self.current_time
            harvests = []
            for A in self.population:
                harvest = A.perform_action(dt)
                harvests.append(harvest)
            self.current_time += dt
            
            # Update agent strategy
            agent = self.population[agent_index]
            neighbor = self.population[neighbor_index]
            decision = agent.decide_update(harvests[agent_index], harvests[neighbor_index])
            if decision == 'imitate':
                agent.strategy = neighbor.strategy

            # Check consensus
            self.consensus = self.check_for_consensus()
            if self.consensus:
                return 1  # end with consensus

        return 0  # end without consensus

    def get_strategies(self):
        return np.array([agent.strategy for agent in self.population])

    def get_stocks(self):
        return np.array([agent.resource_pool.stock for agent in self.population])


#### Parameters #### 

num_agents = 50
initial_stock = 1.0
max_stock = 1.0
growth_rate = 1.0
rationality = 1.0
update_timescale = 1.0
link_density = 0.35

#### Main code ####

population = [
    Agent(
        np.random.randint(2),
        rationality,
        ResourcePool(initial_stock, max_stock, growth_rate)
    )
    for _ in range(num_agents)
]

adjacency_matrix = nx.adjacency_matrix(nx.erdos_renyi_graph(num_agents, link_density)).toarray()

trainer = MultiAgentTrainer(adjacency_matrix, population, update_timescale)
consensus = trainer.run()

print("Consensus:", bool(consensus))
print("--- Fraction of sustainable agents:", trainer.get_strategies().mean())
print("--- Model time:", trainer.current_time)
